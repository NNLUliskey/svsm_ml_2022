{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea18b50-839c-41b9-89dc-b9bc831f76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import wfdb\n",
    "import copy as cp\n",
    "import scipy.signal as signal\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8fc3db-52ee-45aa-aa1e-2c5c2f0cfced",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_list = [] # Initialize the array that will hold the list of our records\n",
    "\n",
    "records = 'mit-bih-dataframes/subject_list.csv' # Get our record list like we did in the initial extraction\n",
    "with open(records) as rfile:# Load our records into the array\n",
    "    for record in rfile:\n",
    "        record = record[0:-1] # The -1 removes the newline (\"\\n\") character from the string\n",
    "        record_list.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b2cde7-7b84-472e-b606-bddb254baaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/23 [00:00<?, ?it/s]C:\\Users\\galyn\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [04:22<00:00, 11.42s/it]\n"
     ]
    }
   ],
   "source": [
    "subject_dataframes = [] # Initialize our dataframe array\n",
    "\n",
    "for x in tqdm(record_list): # Extract our dataframes from the CSVs we saved previously\n",
    "    subject_dataframes.append(pd.read_csv('mit-bih-dataframes/'+x+'.csv', index_col=0))\n",
    "            # 'index_col=0' loads the index that is saved into the csv as the index rather than another column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f880d2c8-b7b1-4292-9406-552ee27b6d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [01:17<00:00,  3.36s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now we get the indexes of the R-Peaks from our dataframes\n",
    "qrs = [] # Initialize the array that will hold our list of R-Peaks for each subject\n",
    "qrs_colors= []\n",
    "for subject in tqdm(subject_dataframes): # Load each subject\n",
    "    qrs.append([idx for idx, x in enumerate(subject['R-Peak']) if x]) # Then we use list comprehension to get our r peaks for each subject\n",
    "                                                                # Recall, the indices that the R-Peak column is true is where there is an r-peak\n",
    "                                                                # So, we iterate through and identify which indices that is for each subject\n",
    "for idx, subj in enumerate(tqdm(qrs)):    \n",
    "    df_color = []\n",
    "    for x in subj: \n",
    "        if subject_dataframes[idx].loc[x, 'Normal']: \n",
    "            df_color.append('Normal')\n",
    "        elif subject_dataframes[idx].loc[x, 'AFIB']:\n",
    "            df_color.append('AFIB')\n",
    "        else: \n",
    "            df_color.append('Other')\n",
    "    qrs_colors.append(df_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a8abf7-2456-4f5d-83ef-2af81e343adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44005 44005\n"
     ]
    }
   ],
   "source": [
    "print(len(qrs_colors[0]),len(qrs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e020578e-01d7-42f7-8748-495837653a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 14.56it/s]\n"
     ]
    }
   ],
   "source": [
    "rr_ints = [] # Initialize the array that will hold all of our subjects' RR-Intervals\n",
    "rhythms = []\n",
    "for idx, subj in enumerate(tqdm(qrs)): # Iterate through our subjects data\n",
    "    rrlabels = qrs_colors[idx]\n",
    "    s_labels = []\n",
    "    rr1 = [] # Initialize a temporary array that will store a single subject's RR-Intervals\n",
    "    for idxs, r in enumerate(subj): # Iterate through the subject's R-Peaks\n",
    "        if idxs == 0: # If it is the first peak we have no interval so go on to the next R-Peak\n",
    "            next\n",
    "        else:\n",
    "            rr1.append(r - subj[idxs-1]) # Find the interval by taking the difference of the location of one R-Peak with the Location of the R-Peak before it\n",
    "            s_labels.append(rrlabels[idxs])\n",
    "    rr_ints.append(rr1) # Add it to our master array\n",
    "    rhythms.append(s_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "561f90a2-6c6b-4f41-a0f5-533c17402c6e",
   "metadata": {},
   "source": [
    "rr_ints = [] # Initialize the array that will hold all of our subjects' RR-Intervals\n",
    "\n",
    "for idx, subj in enumerate(record_list): # Iterate through our subject ids\n",
    "    rr_ints.append(np.genfromtxt('mit-bih-rr-intervals/'+str(subj)+'.csv',delimiter=',')) # Add to master array\n",
    "       #NOTE = change 'mit-bih-rr-intervals/' to the appropriate location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484c80b5-5df1-412c-8391-e38b0a9f118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:00, 30.92it/s]\n"
     ]
    }
   ],
   "source": [
    "outlier_list=[]\n",
    "rrs=[]\n",
    "for idx, subj in tqdm(enumerate(rr_ints)):\n",
    "    outlier = [[],[]] # I want to store the index and the outlier\n",
    "    for idx2, rr in enumerate(subj):\n",
    "        if rr > 500:\n",
    "            outlier[0].append(rr) # add the rr int to our list\n",
    "            outlier[1].append(idx2) # Add its index to our list\n",
    "    subj = np.delete(subj, outlier[1]) # Remove all found outliers from our subject \n",
    "    rhythms[idx] = np.delete(rhythms[idx], outlier[1])\n",
    "    rrs.append(subj) # Add it to our new rr interval list\n",
    "    outlier_list.append(outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f1d7c3-c31a-45b6-9e38-d0c3e2077729",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Setup subset dictionary\n",
    "subset_list = {}\n",
    "subset_rhythm_labels = {}\n",
    "for x in record_list:\n",
    "    subset_list[x] = []\n",
    "    subset_rhythm_labels[x] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2935fd-a903-4f38-acd3-ea27100d292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:07,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "subset_len_sec = 25 # Set the time we are going to subset by\n",
    "subset_len_samp = subset_len_sec*250 # Get that timme in samplse\n",
    "\n",
    "for idx, subj in tqdm(enumerate(rrs)):\n",
    "    samp = 0\n",
    "    while samp < len(subj):\n",
    "        subs_len = 0\n",
    "        subs = []\n",
    "        rhythm_list = []\n",
    "        while subs_len < subset_len_samp and samp<len(subj):\n",
    "            rr = subj[samp]\n",
    "            subs.append(rr)\n",
    "            rhythm_list.append(rhythms[idx][samp])\n",
    "            subs_len+=rr\n",
    "            samp+=1\n",
    "        majority_rhythm = np.unique(rhythm_list)[np.argmax(np.unique(rhythm_list, return_counts=True)[1])]\n",
    "        subset_list[record_list[idx]].append(subs)\n",
    "        subset_rhythm_labels[record_list[idx]].append(majority_rhythm)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04528378-e826-4753-b5d2-c03ce1810482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [07:21<00:00, 19.21s/it]\n"
     ]
    }
   ],
   "source": [
    "subset_record_list = []\n",
    "reload_flag=True\n",
    "for idx, x in enumerate(tqdm(record_list)): \n",
    "    subset_record_list = []\n",
    "    for num, subset in enumerate(subset_list[x]):\n",
    "        if not os.path.exists('mit_bih_subset/'+x+ '-'+str(num)+'.csv') or reload_flag:\n",
    "            np.savetxt('mit_bih_subset/'+x+ '-'+str(num)+'.csv', subset, delimiter=\",\",  fmt='%s') \n",
    "            \n",
    "            subset_record_list.append(x+ '-'+str(num)+'.csv')\n",
    "    if not os.path.exists('mit_bih_subset/'+x +'.csv') or reload_flag:\n",
    "        pd.DataFrame({'subsetID': subset_record_list, 'rhythmLabel': subset_rhythm_labels[x]}).to_csv('mit_bih_subset/'+x+'_subset_dataframe.csv')\n",
    "            # We'll load the complete list of subjects as well so that we can easily recreate the file names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
