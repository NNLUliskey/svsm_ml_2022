{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMS-Sapkals\\AppData\\Local\\Temp\\ipykernel_2384\\4110068169.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('retina')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 70 #display 70 dpi in Jupyter Notebook, may consider100 dpi \n",
    "plt.rcParams['savefig.dpi'] = 300 #define 300 dpi for saving figures\n",
    "\n",
    "import seaborn as sns\n",
    "## here are some settings \n",
    "sns.set_style('whitegrid')\n",
    "sns.set(rc={\"figure.dpi\":70, 'savefig.dpi':300}) #defining dpi setting\n",
    "sns.set_context('notebook')\n",
    "sns.set_style(\"ticks\")\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "---Run time is 0.00012199999764561653 seconds ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tells matplotlib to display images inline instead of a new window\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "import timeit #imports timeit module\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "start_time = timeit.default_timer() #defines start time so computational time can be calculated\n",
    "print(\"Hello World\")\n",
    "elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "print(\"---Run time is %s seconds ---\" % elapsed) #prints computation time\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import statistics\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import neighbors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tqdm import tqdm\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampto must be greater than sampfrom\n",
      "sampto must be greater than sampfrom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:15<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# cwd = os.getcwd()\n",
    "# print(cwd)\n",
    "# os.chdir('/Users/chenc/000---STT450-Jupyter Notebook/000--STT450-550/') \n",
    "#data = load_breast_cancer(as_frame = True); \n",
    "#df = data.frame; \n",
    "#print(df.shape)\n",
    "# In this block use the code we looked at on 6/30 as a reference to save our rr-intervals as a .\n",
    "rlist = []\n",
    "records = 'mit-bih-raw\\RECORDS' # Replace the _______ with the name of the records file in your MIT-BIH data folder\n",
    "with open(records) as rfile: #Then we open the file \n",
    "                             #The 'with' command only opens the file while we are in it. Automatically closes the file when we're not\n",
    "    for record in rfile:  # Then we iterate through the lines in the file\n",
    "        record = record[0:len(record)-1] # Remove any erronious new line characters at the end ('\\n')\n",
    "        rlist.append(record) # Then build an array with it\n",
    "        \n",
    "\n",
    "###### Step 1: Initialize all Arrays\n",
    "             # Below, replace all of the ___ with the command that declares an array/list\n",
    "             # hint: https://stackoverflow.com/questions/1514553/how-to-declare-an-array-in-python\n",
    "samples = [] # will house the samples of all subjects\n",
    "good_list = [] # will list the names of the subjects we successfully extracted\n",
    "bad_list = [] # will house the names of the subjects we failed to extract\n",
    "qrs = [] # will house the indices of R-Peaks for all subjects\n",
    "atr_label = [] # will house the labels for each rhythm annotation for all subjects\n",
    "atr_locs = [] # will house the locations corresponding to the rhythm annotation labels\n",
    "\n",
    "\n",
    "###### Step 2: Extract Information\n",
    "for x in tqdm(rlist): #this will iterate through te records that we found above\n",
    "  \n",
    "    try: # A try statement will run the except statement if for some reason the try commands fail\n",
    "         # In this case I use the try statement because one of the subjects has no signal data causing failure\n",
    "         # I then use bad_list and good_list so that all of the indices in rlist match with the arrays we initialized in Step 1, above\n",
    "        ######################################################\n",
    "            # Below find the wfdb function that will return the information that is described below \n",
    "        # Then replace _____ with the correct function call\n",
    "        samp = wfdb.rdsamp('mit-bih-raw/'+x) # wfdb._____(file_location) will read the signal & header data and return a 2 value array\n",
    "            # samp[0] - the signal data is the raw reading from the ecg. Each value is a sample taken.\n",
    "            # samp[1] - the header data includes things about the signal data such as:\n",
    "              # samples per section, denoted 'fs'\n",
    "              # number of signals, denoted 'n_sig'\n",
    "            \n",
    "        ######################################################\n",
    "        samples.append(samp) #add it to our array for all subject\n",
    "            #What is our file extension that has the annotation we want? Find it here and replace _____ with it \n",
    "            #hint: READ THE VARIABLE NAMES!!!!\n",
    "        qrs_tmp = wfdb.rdann('mit-bih-raw/'+x, extension='qrs') #extract the QRS Info\n",
    "        qrs_locs = np.array(qrs_tmp.sample, dtype='int') #Get just the loccation of R-Peaks from the QRS Info\n",
    "        qrs.append(qrs_locs) # Add to our array for all subjects\n",
    "        \n",
    "            #Do the same thing here\n",
    "        atr = wfdb.rdann('mit-bih-raw/'+x,extension='atr') #extract the atr info which stores the rhythm type(s) over the whole signal\n",
    "        atr_label.append(atr.aux_note) # aux_note stores the type of rhythm - main two are '(N' for normal and '(AFIB' for AFIB\n",
    "        atr_locs.append(np.append(atr.sample, len(samp[0]))) #I add the length of the whole sample to the end for better visualization later\n",
    "        \n",
    "        good_list.append(x) # when all extraction is successful append the record name to good_list\n",
    "    except Exception as exep:\n",
    "        print(exep) # Alert the user of an exception\n",
    "        bad_list.append(x) # add to the bad list\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = pd.read_csv('Data/Carseats.csv')\n",
    "# #df3.info()\n",
    "# print(); df3.head(5)\n",
    "features_df_list = []\n",
    "for subject in good_list:\n",
    "    data = pd.read_csv(f'subject-features-dataframes/subject{subject}.csv')\n",
    "    data = data.assign(Subject = subject)\n",
    "    #print(data)\n",
    "    features_df_list.append(data)\n",
    "features_maindf = pd.concat(features_df_list, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['High'] = df3.Sales.map(lambda x: 1 if x>8 else 0)\n",
    "# df3.ShelveLoc = pd.factorize(df3.ShelveLoc)[0]\n",
    "# df3.Urban = df3.Urban.map({'No':0, 'Yes':1})\n",
    "# df3.US = df3.US.map({'No':0, 'Yes':1})\n",
    "# #df3.info()\n",
    "# print(); df3.head(5)\n",
    "#X = df3.drop(['Sales', 'High'], axis = 1)\n",
    "#y = df3.High\n",
    "##print(X.shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>StoS</th>\n",
       "      <th>StoR</th>\n",
       "      <th>StoL</th>\n",
       "      <th>RtoS</th>\n",
       "      <th>RtoR</th>\n",
       "      <th>RtoL</th>\n",
       "      <th>LtoS</th>\n",
       "      <th>LtoR</th>\n",
       "      <th>LtoL</th>\n",
       "      <th>STD</th>\n",
       "      <th>CoefVar</th>\n",
       "      <th>Range</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>ShEn</th>\n",
       "      <th>AppEn</th>\n",
       "      <th>SampEn</th>\n",
       "      <th>Rhythm</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.180045</td>\n",
       "      <td>0.259401</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.024543</td>\n",
       "      <td>1.050913</td>\n",
       "      <td>0.807078</td>\n",
       "      <td>1.004927</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181063</td>\n",
       "      <td>0.314259</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.915595</td>\n",
       "      <td>0.722627</td>\n",
       "      <td>0.867501</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176833</td>\n",
       "      <td>0.224044</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.033321</td>\n",
       "      <td>1.038812</td>\n",
       "      <td>0.780945</td>\n",
       "      <td>0.871395</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166312</td>\n",
       "      <td>0.240948</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>0.917357</td>\n",
       "      <td>0.551398</td>\n",
       "      <td>0.559616</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.190016</td>\n",
       "      <td>0.289659</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.033423</td>\n",
       "      <td>0.989094</td>\n",
       "      <td>0.638499</td>\n",
       "      <td>0.850539</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>1743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.014536</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083382</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>1744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>0.024859</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.167944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083382</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>1745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016860</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083382</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>1746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024815</td>\n",
       "      <td>0.030645</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.167944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083382</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>1747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020615</td>\n",
       "      <td>0.025387</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.167944</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.087315</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1748 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      StoS      StoR      StoL      RtoS      RtoR      RtoL  \\\n",
       "0              0  0.250000  0.125000  0.083333  0.083333  0.208333  0.083333   \n",
       "1              1  0.208333  0.166667  0.041667  0.166667  0.291667  0.041667   \n",
       "2              2  0.083333  0.083333  0.166667  0.041667  0.375000  0.041667   \n",
       "3              3  0.166667  0.125000  0.000000  0.083333  0.416667  0.083333   \n",
       "4              4  0.291667  0.208333  0.041667  0.125000  0.000000  0.125000   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1743        1743  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000   \n",
       "1744        1744  0.000000  0.041667  0.000000  0.000000  0.958333  0.000000   \n",
       "1745        1745  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000   \n",
       "1746        1746  0.000000  0.041667  0.000000  0.000000  0.958333  0.000000   \n",
       "1747        1747  0.000000  0.041667  0.000000  0.000000  0.958333  0.000000   \n",
       "\n",
       "          LtoS      LtoR      LtoL       STD   CoefVar  Range  Volatility  \\\n",
       "0     0.083333  0.041667  0.041667  0.180045  0.259401  0.620    0.024543   \n",
       "1     0.041667  0.041667  0.000000  0.181063  0.314259  0.584    0.034714   \n",
       "2     0.166667  0.041667  0.000000  0.176833  0.224044  0.620    0.033321   \n",
       "3     0.041667  0.041667  0.041667  0.166312  0.240948  0.544    0.019996   \n",
       "4     0.166667  0.000000  0.041667  0.190016  0.289659  0.552    0.033423   \n",
       "...        ...       ...       ...       ...       ...    ...         ...   \n",
       "1743  0.000000  0.000000  0.000000  0.011808  0.014536  0.064    0.000326   \n",
       "1744  0.000000  0.000000  0.000000  0.020241  0.024859  0.088    0.000604   \n",
       "1745  0.000000  0.000000  0.000000  0.016860  0.020821  0.076    0.000486   \n",
       "1746  0.000000  0.000000  0.000000  0.024815  0.030645  0.080    0.000595   \n",
       "1747  0.000000  0.000000  0.000000  0.020615  0.025387  0.100    0.000756   \n",
       "\n",
       "          ShEn     AppEn    SampEn  Rhythm Subject  \n",
       "0     1.050913  0.807078  1.004927       0   04015  \n",
       "1     0.915595  0.722627  0.867501       0   04015  \n",
       "2     1.038812  0.780945  0.871395       0   04015  \n",
       "3     0.917357  0.551398  0.559616       0   04015  \n",
       "4     0.989094  0.638499  0.850539       0   04015  \n",
       "...        ...       ...       ...     ...     ...  \n",
       "1743  0.000000  0.000000  0.083382       0   04015  \n",
       "1744  0.167944  0.000000  0.083382       0   04015  \n",
       "1745  0.000000  0.000000  0.083382       0   04015  \n",
       "1746  0.167944  0.000000  0.083382       0   04015  \n",
       "1747  0.167944  0.003828  0.087315       0   04015  \n",
       "\n",
       "[1748 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values = ['StoS', 'StoR', 'StoL', 'RtoS', 'RtoR', 'RtoL', 'LtoS',\n",
    "       'LtoR', 'LtoL', 'STD', 'CoefVar', 'Range', 'Volatility', 'ShEn',\n",
    "       'AppEn', 'SampEn']\n",
    "y_values = ['Rhythm']\n",
    "features_df_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An AdaBoost classifier.\n",
    "\n",
    "The argument `n_estimators = 500` indicates that we want 500 trees\n",
    "\n",
    "class sklearn.ensemble.AdaBoostClassifier(base_estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [3:55:49, 615.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Run time is 14165.9980229 seconds ---\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.9090389016018307, 0.9533468559837728, 0.9949622166246851, 0.9286570743405276, 0.9958202716823407, 0.9464503042596348, 0.8239140588510042, 0.9972770592239619, 0.9437751004016064, 0.9735391400220507, 0.984573502722323, 0.9892318736539842, 0.744671201814059, 0.9554140127388535, 0.5628642797668609, 0.9871510855117412, 0.9890335846470185, 0.9803808424697057, 0.6935756551141167, 0.9785596481583287, 0.9961505560307955, 0.9968612680477087, 0.9957716701902748]\n",
      "\n",
      "Avg accuracy : \n",
      "0.9270008766894428\n",
      "\n",
      "Std of accuracy : \n",
      "0.11120923491905742\n",
      "[0.9090389016018307, 0.9533468559837728, 0.9949622166246851, 0.9286570743405276, 0.9958202716823407, 0.9464503042596348, 0.8239140588510042, 0.9972770592239619, 0.9437751004016064, 0.9735391400220507, 0.984573502722323, 0.9892318736539842, 0.744671201814059, 0.9554140127388535, 0.5628642797668609, 0.9871510855117412, 0.9890335846470185, 0.9803808424697057, 0.6935756551141167, 0.9785596481583287, 0.9961505560307955, 0.9968612680477087, 0.9957716701902748]\n",
      "[[22769  1974]\n",
      " [ 1707 18518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     24743\n",
      "           1       0.90      0.92      0.91     20225\n",
      "\n",
      "    accuracy                           0.92     44968\n",
      "   macro avg       0.92      0.92      0.92     44968\n",
      "weighted avg       0.92      0.92      0.92     44968\n",
      "\n",
      "[525, 525, 514, 525, 525, 525, 514, 525, 496, 522, 525, 522, 519, 525, 525, 525, 525, 525, 514, 522, 522, 514, 522]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=23)\n",
    "#for df in features_df_list:\n",
    "df = features_maindf\n",
    "acc_score = [];\n",
    "Truth = [];\n",
    "Output = [];\n",
    "n_estimators_list = []\n",
    "#max_depth_list = []\n",
    "for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "    train_index = ~df['Subject'].str.contains(subject)\n",
    "    test_index = df['Subject'].str.contains(subject)\n",
    "    X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "    y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "\n",
    "    temp_model = AdaBoostClassifier(n_estimators=500, learning_rate = 0.1, algorithm=\"SAMME.R\", random_state=2)\n",
    "    param_distributions = {'n_estimators': randint(475, 526)}\n",
    "    search = RandomizedSearchCV(estimator=temp_model, param_distributions=param_distributions, random_state=0)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    n_estimators_list.append(search.best_params_['n_estimators'])\n",
    "    #max_depth_list.append(search.best_params_['max_depth'])\n",
    "\n",
    "    model = AdaBoostClassifier(n_estimators=search.best_params_['n_estimators'], \n",
    "                               learning_rate=0.1,algorithm=\"SAMME.R\", random_state=2)\n",
    "    model.fit(X_train, y_train)    \n",
    "\n",
    "    #model = AdaBoostClassifier(n_estimators=500, learning_rate = 0.1, algorithm=\"SAMME.R\", random_state=2)\n",
    "    #model.fit(X_train,y_train)\n",
    "\n",
    "    pred_values = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "    acc = accuracy_score(y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "    \n",
    "    Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "    Output.extend(pred_values); ## it is a list\n",
    "elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "print(\"---Run time is %s seconds ---\" % elapsed) #prints computation time\n",
    "print()\n",
    "\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print()\n",
    "print('Avg accuracy : \\n{}'.format(np.mean(acc_score))); \n",
    "print()\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print(acc_score)\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print(classification_report(Truth, Output))\n",
    "print(n_estimators_list)\n",
    "temp_list = []\n",
    "temp_idx = []\n",
    "n_estimators_best = []\n",
    "max_depth_best = []\n",
    "for acc in acc_score:\n",
    "    if acc >= 0.95:\n",
    "        temp_list.append(acc)\n",
    "        temp_idx.append(acc_score.index(acc))\n",
    "for idx in temp_idx:\n",
    "    n_estimators_best.append(n_estimators_list[idx])\n",
    "    #max_depth_best.append(max_depth_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [3:54:48, 612.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Run time is 28254.433449800003 seconds ---\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.9090389016018307, 0.9533468559837728, 0.9949622166246851, 0.9286570743405276, 0.9958202716823407, 0.9464503042596348, 0.8215787015413358, 0.9972770592239619, 0.9442771084337349, 0.9729878721058435, 0.984573502722323, 0.9892318736539842, 0.744671201814059, 0.9554140127388535, 0.5628642797668609, 0.9871510855117412, 0.9890335846470185, 0.9803808424697057, 0.6935756551141167, 0.9785596481583287, 0.9961505560307955, 0.9968612680477087, 0.9957716701902748]\n",
      "\n",
      "Avg accuracy : \n",
      "0.9268971976810192\n",
      "\n",
      "Std of accuracy : \n",
      "0.11129770957079084\n",
      "[0.9090389016018307, 0.9533468559837728, 0.9949622166246851, 0.9286570743405276, 0.9958202716823407, 0.9464503042596348, 0.8215787015413358, 0.9972770592239619, 0.9442771084337349, 0.9729878721058435, 0.984573502722323, 0.9892318736539842, 0.744671201814059, 0.9554140127388535, 0.5628642797668609, 0.9871510855117412, 0.9890335846470185, 0.9803808424697057, 0.6935756551141167, 0.9785596481583287, 0.9961505560307955, 0.9968612680477087, 0.9957716701902748]\n",
      "[[22768  1975]\n",
      " [ 1711 18514]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     24743\n",
      "           1       0.90      0.92      0.91     20225\n",
      "\n",
      "    accuracy                           0.92     44968\n",
      "   macro avg       0.92      0.92      0.92     44968\n",
      "weighted avg       0.92      0.92      0.92     44968\n",
      "\n",
      "[525, 525, 514, 525, 525, 525, 514, 525, 496, 522, 525, 522, 519, 525, 525, 525, 525, 525, 514, 522, 522, 514, 522, 525, 525, 514, 525, 525, 525, 514, 525, 496, 522, 525, 522, 519, 525, 525, 525, 525, 525, 514, 522, 522, 514, 522]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=23)\n",
    "#for df in features_df_list:\n",
    "df = features_maindf\n",
    "acc_score = [];\n",
    "Truth = [];\n",
    "Output = [];\n",
    "# n_estimators_list = []\n",
    "import statistics\n",
    "mode_estimators = statistics.mode(n_estimators_best)\n",
    "#max_depth_list = []\n",
    "for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "    train_index = ~df['Subject'].str.contains(subject)\n",
    "    test_index = df['Subject'].str.contains(subject)\n",
    "    X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "    y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "\n",
    "    temp_model = AdaBoostClassifier(n_estimators=500, learning_rate = 0.1, algorithm=\"SAMME.R\", random_state=2)\n",
    "    param_distributions = {'n_estimators': randint(475, 526)}\n",
    "    search = RandomizedSearchCV(estimator=temp_model, param_distributions=param_distributions, random_state=0)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    n_estimators_list.append(search.best_params_['n_estimators'])\n",
    "    #max_depth_list.append(search.best_params_['max_depth'])\n",
    "\n",
    "    model = AdaBoostClassifier(n_estimators=mode_estimators, \n",
    "                               learning_rate=0.1,algorithm=\"SAMME.R\", random_state=2)\n",
    "    model.fit(X_train, y_train)    \n",
    "\n",
    "    #model = AdaBoostClassifier(n_estimators=500, learning_rate = 0.1, algorithm=\"SAMME.R\", random_state=2)\n",
    "    #model.fit(X_train,y_train)\n",
    "\n",
    "    pred_values = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "    acc = accuracy_score(y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "    \n",
    "    Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "    Output.extend(pred_values); ## it is a list\n",
    "elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "print(\"---Run time is %s seconds ---\" % elapsed) #prints computation time\n",
    "print()\n",
    "\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print()\n",
    "print('Avg accuracy : \\n{}'.format(np.mean(acc_score))); \n",
    "print()\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print(acc_score)\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print(classification_report(Truth, Output))\n",
    "print(n_estimators_list)\n",
    "# temp_list = []\n",
    "# temp_idx = []\n",
    "# n_estimators_best = []\n",
    "# max_depth_best = []\n",
    "# for acc in acc_score:\n",
    "#     if acc >= 0.95:\n",
    "#         temp_list.append(acc)\n",
    "#         temp_idx.append(acc_score.index(acc))\n",
    "# for idx in temp_idx:\n",
    "#     n_estimators_best.append(n_estimators_list[idx])\n",
    "#     max_depth_best.append(max_depth_list[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afib",
   "language": "python",
   "name": "afib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
