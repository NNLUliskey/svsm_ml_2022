{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 70 #display 70 dpi in Jupyter Notebook, may consider100 dpi \n",
    "plt.rcParams['savefig.dpi'] = 300 #define 300 dpi for saving figures\n",
    "\n",
    "import seaborn as sns\n",
    "## here are some settings \n",
    "sns.set_style('whitegrid')\n",
    "sns.set(rc={\"figure.dpi\":70, 'savefig.dpi':300}) #defining dpi setting\n",
    "sns.set_context('notebook')\n",
    "sns.set_style(\"ticks\")\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "---Run time is 0.0003207610000117711 seconds ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tells matplotlib to display images inline instead of a new window\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "import timeit #imports timeit module\n",
    "start_time = timeit.default_timer() #defines start time so computational time can be calculated\n",
    "print(\"Hello World\")\n",
    "elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "print(\"---Run time is %s seconds ---\" % elapsed) #prints computation time\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import neighbors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tqdm import tqdm\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampto must be greater than sampfrom\n",
      "sampto must be greater than sampfrom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:25<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# cwd = os.getcwd()\n",
    "# print(cwd)\n",
    "# os.chdir('/Users/chenc/000---STT450-Jupyter Notebook/000--STT450-550/') \n",
    "#data = load_breast_cancer(as_frame = True); \n",
    "#df = data.frame; \n",
    "#print(df.shape)\n",
    "# In this block use the code we looked at on 6/30 as a reference to save our rr-intervals as a .\n",
    "rlist = []\n",
    "records = 'mit-bih-raw\\RECORDS' # Replace the _______ with the name of the records file in your MIT-BIH data folder\n",
    "with open(records) as rfile: #Then we open the file \n",
    "                             #The 'with' command only opens the file while we are in it. Automatically closes the file when we're not\n",
    "    for record in rfile:  # Then we iterate through the lines in the file\n",
    "        record = record[0:len(record)-1] # Remove any erronious new line characters at the end ('\\n')\n",
    "        rlist.append(record) # Then build an array with it\n",
    "        \n",
    "\n",
    "###### Step 1: Initialize all Arrays\n",
    "             # Below, replace all of the ___ with the command that declares an array/list\n",
    "             # hint: https://stackoverflow.com/questions/1514553/how-to-declare-an-array-in-python\n",
    "samples = [] # will house the samples of all subjects\n",
    "good_list = [] # will list the names of the subjects we successfully extracted\n",
    "bad_list = [] # will house the names of the subjects we failed to extract\n",
    "qrs = [] # will house the indices of R-Peaks for all subjects\n",
    "atr_label = [] # will house the labels for each rhythm annotation for all subjects\n",
    "atr_locs = [] # will house the locations corresponding to the rhythm annotation labels\n",
    "\n",
    "\n",
    "###### Step 2: Extract Information\n",
    "for x in tqdm(rlist): #this will iterate through te records that we found above\n",
    "  \n",
    "    try: # A try statement will run the except statement if for some reason the try commands fail\n",
    "         # In this case I use the try statement because one of the subjects has no signal data causing failure\n",
    "         # I then use bad_list and good_list so that all of the indices in rlist match with the arrays we initialized in Step 1, above\n",
    "        ######################################################\n",
    "            # Below find the wfdb function that will return the information that is described below \n",
    "        # Then replace _____ with the correct function call\n",
    "        samp = wfdb.rdsamp('mit-bih-raw/'+x) # wfdb._____(file_location) will read the signal & header data and return a 2 value array\n",
    "            # samp[0] - the signal data is the raw reading from the ecg. Each value is a sample taken.\n",
    "            # samp[1] - the header data includes things about the signal data such as:\n",
    "              # samples per section, denoted 'fs'\n",
    "              # number of signals, denoted 'n_sig'\n",
    "            \n",
    "        ######################################################\n",
    "        samples.append(samp) #add it to our array for all subject\n",
    "            #What is our file extension that has the annotation we want? Find it here and replace _____ with it \n",
    "            #hint: READ THE VARIABLE NAMES!!!!\n",
    "        qrs_tmp = wfdb.rdann('mit-bih-raw/'+x, extension='qrs') #extract the QRS Info\n",
    "        qrs_locs = np.array(qrs_tmp.sample, dtype='int') #Get just the loccation of R-Peaks from the QRS Info\n",
    "        qrs.append(qrs_locs) # Add to our array for all subjects\n",
    "        \n",
    "            #Do the same thing here\n",
    "        atr = wfdb.rdann('mit-bih-raw/'+x,extension='atr') #extract the atr info which stores the rhythm type(s) over the whole signal\n",
    "        atr_label.append(atr.aux_note) # aux_note stores the type of rhythm - main two are '(N' for normal and '(AFIB' for AFIB\n",
    "        atr_locs.append(np.append(atr.sample, len(samp[0]))) #I add the length of the whole sample to the end for better visualization later\n",
    "        \n",
    "        good_list.append(x) # when all extraction is successful append the record name to good_list\n",
    "    except Exception as exep:\n",
    "        print(exep) # Alert the user of an exception\n",
    "        bad_list.append(x) # add to the bad list\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = pd.read_csv('Data/Carseats.csv')\n",
    "# #df3.info()\n",
    "# print(); df3.head(5)\n",
    "features_df_list = []\n",
    "for subject in good_list:\n",
    "    data = pd.read_csv(f'subject-features-dataframes/subject{subject}.csv')\n",
    "    data = data.assign(Subject = subject)\n",
    "    #print(data)\n",
    "    features_df_list.append(data)\n",
    "features_maindf = pd.concat(features_df_list, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['High'] = df3.Sales.map(lambda x: 1 if x>8 else 0)\n",
    "# df3.ShelveLoc = pd.factorize(df3.ShelveLoc)[0]\n",
    "# df3.Urban = df3.Urban.map({'No':0, 'Yes':1})\n",
    "# df3.US = df3.US.map({'No':0, 'Yes':1})\n",
    "# #df3.info()\n",
    "# print(); df3.head(5)\n",
    "#X = df3.drop(['Sales', 'High'], axis = 1)\n",
    "#y = df3.High\n",
    "##print(X.shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>StoS</th>\n",
       "      <th>StoR</th>\n",
       "      <th>StoL</th>\n",
       "      <th>RtoS</th>\n",
       "      <th>RtoR</th>\n",
       "      <th>RtoL</th>\n",
       "      <th>LtoS</th>\n",
       "      <th>LtoR</th>\n",
       "      <th>LtoL</th>\n",
       "      <th>STD</th>\n",
       "      <th>CoefVar</th>\n",
       "      <th>Range</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>ShEn</th>\n",
       "      <th>AppEn</th>\n",
       "      <th>SampEn</th>\n",
       "      <th>Rhythm</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.180045</td>\n",
       "      <td>0.259401</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.024543</td>\n",
       "      <td>1.050913</td>\n",
       "      <td>0.807078</td>\n",
       "      <td>1.004927</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181063</td>\n",
       "      <td>0.314259</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.915595</td>\n",
       "      <td>0.722627</td>\n",
       "      <td>0.867501</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176833</td>\n",
       "      <td>0.224044</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.033321</td>\n",
       "      <td>1.038812</td>\n",
       "      <td>0.780945</td>\n",
       "      <td>0.871395</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166312</td>\n",
       "      <td>0.240948</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>0.917357</td>\n",
       "      <td>0.551398</td>\n",
       "      <td>0.559616</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.190016</td>\n",
       "      <td>0.289659</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.033423</td>\n",
       "      <td>0.989094</td>\n",
       "      <td>0.638499</td>\n",
       "      <td>0.850539</td>\n",
       "      <td>0</td>\n",
       "      <td>04015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44963</th>\n",
       "      <td>2360</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.160217</td>\n",
       "      <td>0.265050</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>1.038812</td>\n",
       "      <td>0.876587</td>\n",
       "      <td>1.116470</td>\n",
       "      <td>1</td>\n",
       "      <td>08455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>2361</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131288</td>\n",
       "      <td>0.230363</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.029151</td>\n",
       "      <td>1.050913</td>\n",
       "      <td>0.743082</td>\n",
       "      <td>0.842679</td>\n",
       "      <td>1</td>\n",
       "      <td>08455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44965</th>\n",
       "      <td>2362</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280151</td>\n",
       "      <td>0.453378</td>\n",
       "      <td>1.304</td>\n",
       "      <td>0.247255</td>\n",
       "      <td>0.973253</td>\n",
       "      <td>0.748702</td>\n",
       "      <td>0.796005</td>\n",
       "      <td>1</td>\n",
       "      <td>08455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44966</th>\n",
       "      <td>2363</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.177207</td>\n",
       "      <td>0.311107</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.054405</td>\n",
       "      <td>1.050913</td>\n",
       "      <td>0.937331</td>\n",
       "      <td>1.217672</td>\n",
       "      <td>1</td>\n",
       "      <td>08455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44967</th>\n",
       "      <td>2364</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107706</td>\n",
       "      <td>0.233412</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.017459</td>\n",
       "      <td>0.976895</td>\n",
       "      <td>0.744767</td>\n",
       "      <td>0.812494</td>\n",
       "      <td>1</td>\n",
       "      <td>08455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44968 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      StoS      StoR      StoL      RtoS      RtoR      RtoL  \\\n",
       "0               0  0.250000  0.125000  0.083333  0.083333  0.208333  0.083333   \n",
       "1               1  0.208333  0.166667  0.041667  0.166667  0.291667  0.041667   \n",
       "2               2  0.083333  0.083333  0.166667  0.041667  0.375000  0.041667   \n",
       "3               3  0.166667  0.125000  0.000000  0.083333  0.416667  0.083333   \n",
       "4               4  0.291667  0.208333  0.041667  0.125000  0.000000  0.125000   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "44963        2360  0.291667  0.125000  0.083333  0.083333  0.125000  0.083333   \n",
       "44964        2361  0.250000  0.166667  0.041667  0.041667  0.166667  0.166667   \n",
       "44965        2362  0.250000  0.083333  0.041667  0.041667  0.375000  0.083333   \n",
       "44966        2363  0.166667  0.166667  0.083333  0.083333  0.208333  0.083333   \n",
       "44967        2364  0.166667  0.208333  0.041667  0.208333  0.166667  0.083333   \n",
       "\n",
       "           LtoS      LtoR      LtoL       STD   CoefVar  Range  Volatility  \\\n",
       "0      0.083333  0.041667  0.041667  0.180045  0.259401  0.620    0.024543   \n",
       "1      0.041667  0.041667  0.000000  0.181063  0.314259  0.584    0.034714   \n",
       "2      0.166667  0.041667  0.000000  0.176833  0.224044  0.620    0.033321   \n",
       "3      0.041667  0.041667  0.041667  0.166312  0.240948  0.544    0.019996   \n",
       "4      0.166667  0.000000  0.041667  0.190016  0.289659  0.552    0.033423   \n",
       "...         ...       ...       ...       ...       ...    ...         ...   \n",
       "44963  0.083333  0.083333  0.041667  0.160217  0.265050  0.532    0.029727   \n",
       "44964  0.125000  0.041667  0.000000  0.131288  0.230363  0.504    0.029151   \n",
       "44965  0.083333  0.041667  0.000000  0.280151  0.453378  1.304    0.247255   \n",
       "44966  0.166667  0.000000  0.041667  0.177207  0.311107  0.752    0.054405   \n",
       "44967  0.041667  0.083333  0.000000  0.107706  0.233412  0.412    0.017459   \n",
       "\n",
       "           ShEn     AppEn    SampEn  Rhythm Subject  \n",
       "0      1.050913  0.807078  1.004927       0   04015  \n",
       "1      0.915595  0.722627  0.867501       0   04015  \n",
       "2      1.038812  0.780945  0.871395       0   04015  \n",
       "3      0.917357  0.551398  0.559616       0   04015  \n",
       "4      0.989094  0.638499  0.850539       0   04015  \n",
       "...         ...       ...       ...     ...     ...  \n",
       "44963  1.038812  0.876587  1.116470       1   08455  \n",
       "44964  1.050913  0.743082  0.842679       1   08455  \n",
       "44965  0.973253  0.748702  0.796005       1   08455  \n",
       "44966  1.050913  0.937331  1.217672       1   08455  \n",
       "44967  0.976895  0.744767  0.812494       1   08455  \n",
       "\n",
       "[44968 rows x 19 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values = ['StoS', 'StoR', 'StoL', 'RtoS', 'RtoR', 'RtoL', 'LtoS',\n",
    "       'LtoR', 'LtoL', 'STD', 'CoefVar', 'Range', 'Volatility', 'ShEn',\n",
    "       'AppEn', 'SampEn']\n",
    "y_values = ['Rhythm']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "criterion{“gini”, “entropy”}, default=”gini”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:11,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=23)\n",
    "#for df in features_df_list:\n",
    "df = features_maindf\n",
    "acc_score = [];\n",
    "Truth = [];\n",
    "Output = [];\n",
    "for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "    train_index = ~df['Subject'].str.contains(subject)\n",
    "    test_index = df['Subject'].str.contains(subject)\n",
    "    X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "    y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth=6) #criterion='entropy'\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    pred_values = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "    acc = accuracy_score(y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "    \n",
    "    Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "    Output.extend(pred_values); ## it is a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9073226544622426, 0.9456389452332657, 0.9955919395465995, 0.8872901678657075, 0.9926854754440961, 0.954158215010142, 0.8346567024754787, 0.9979577944179714, 0.929718875502008, 0.958103638368247, 0.9773139745916516, 0.9885139985642498, 0.7868480725623582, 0.943312101910828, 0.5974188176519567, 0.9676561807709348, 0.9862919808087731, 0.9826889786497404, 0.6225697379543533, 0.9120395821880154, 0.9901625320786998, 0.992467043314501, 0.9839323467230444]\n",
      "[[22502  2241]\n",
      " [ 1791 18434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     24743\n",
      "           1       0.89      0.91      0.90     20225\n",
      "\n",
      "    accuracy                           0.91     44968\n",
      "   macro avg       0.91      0.91      0.91     44968\n",
      "weighted avg       0.91      0.91      0.91     44968\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [TN, FP, FN, TP]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(acc_score)\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print(classification_report(Truth, Output))\n",
    "print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The exact results obtained in this section may\n",
    "depend on the version of `python` and the version of the `RandomForestRegressor` package\n",
    "installed on your computer, so don't stress out if you don't match up exactly with the book. Recall that **bagging** is simply a special case of\n",
    "a **random forest** with $m = p$. Therefore, the `RandomForestRegressor()` function can\n",
    "be used to perform both random forests and bagging. Let's start with bagging:\n",
    "\n",
    "\n",
    "### Bagging: using all features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests: use sqrt(p) for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [10:58, 28.64s/it]\n"
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=23)\n",
    "#for df in features_df_list:\n",
    "df = features_maindf\n",
    "acc_score = [];\n",
    "Truth = [];\n",
    "Output = [];\n",
    "#confusion_matrix_df = pd.DataFrame(columns=['TN', 'FP', 'FN', 'TP'])\n",
    "for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "    train_index = ~df['Subject'].str.contains(subject)\n",
    "    test_index = df['Subject'].str.contains(subject)\n",
    "    X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "    y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "\n",
    "    model = RandomForestClassifier(max_features = 10, random_state = 2)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    pred_values = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "    acc = accuracy_score(y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "    #confusion_matrix_df.loc[idx] = confusion_matrix(Truth, Output).ravel()\n",
    "    Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "    Output.extend(pred_values); ## it is a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9147597254004577, 0.9521298174442191, 0.9955919395465995, 0.9268585131894485, 0.9968652037617555, 0.954158215010142, 0.7930873423633816, 0.9979577944179714, 0.9407630522088354, 0.9707828004410143, 0.9823049001814882, 0.9899497487437185, 0.8267573696145125, 0.9490445859872612, 0.6032472939217319, 0.9867080194949047, 0.9883481836874571, 0.9861511829197923, 0.7523245984784447, 0.9708631115997801, 0.9931565440547476, 0.9949780288763339, 0.9953488372093023]\n",
      "[[23105  1638]\n",
      " [ 1707 18518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     24743\n",
      "           1       0.92      0.92      0.92     20225\n",
      "\n",
      "    accuracy                           0.93     44968\n",
      "   macro avg       0.92      0.92      0.92     44968\n",
      "weighted avg       0.93      0.93      0.93     44968\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [TN, FP, FN, TP]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(acc_score)\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print(classification_report(Truth, Output))\n",
    "print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidation = KFold(n_splits=23)\n",
    "# #for df in features_df_list:\n",
    "# df = features_maindf\n",
    "# acc_score = [];\n",
    "# Truth = [];\n",
    "# Output = [];\n",
    "# for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "#     train_index = ~df['Subject'].str.contains(subject)\n",
    "#     test_index = df['Subject'].str.contains(subject)\n",
    "#     X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "#     y_train , y_test = df.loc[train_index,y_values], df.loc[test_index,y_values]\n",
    "\n",
    "#     model = RandomForestClassifier(max_features = 10, random_state = 2)\n",
    "#     model.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#     pred_values = model.predict(X_test)\n",
    "#     pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "#     acc = accuracy_score(y_test, pred_values)\n",
    "#     acc_score.append(acc)\n",
    "    \n",
    "#     Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "#     Output.extend(pred_values); ## it is a list \n",
    "\n",
    "\n",
    "# model = RandomForestClassifier(max_features = 16, random_state = 2)\n",
    "# scores = cross_val_score(model, X, y, cv=crossvalidation)\n",
    "# print('Accuracy of each fold: \\n {}'.format(scores))\n",
    "# print()\n",
    "# print(\"Avg accuracy: {}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An AdaBoost classifier.\n",
    "\n",
    "The argument `n_estimators = 500` indicates that we want 500 trees\n",
    "\n",
    "class sklearn.ensemble.AdaBoostClassifier(base_estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [16:11, 42.24s/it]\n"
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=23)\n",
    "#for df in features_df_list:\n",
    "df = features_maindf\n",
    "acc_score = [];\n",
    "Truth = [];\n",
    "Output = [];\n",
    "for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "    train_index = ~df['Subject'].str.contains(subject)\n",
    "    test_index = df['Subject'].str.contains(subject)\n",
    "    X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "    y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "\n",
    "    model = AdaBoostClassifier(n_estimators=500, learning_rate = 0.1, algorithm=\"SAMME.R\", random_state=2)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    pred_values = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "    acc = accuracy_score(y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "    \n",
    "    Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "    Output.extend(pred_values); ## it is a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9090389016018307, 0.9521298174442191, 0.9949622166246851, 0.9274580335731415, 0.9958202716823407, 0.9464503042596348, 0.8267164876226063, 0.9972770592239619, 0.9437751004016064, 0.9735391400220507, 0.98502722323049, 0.9892318736539842, 0.7419501133786848, 0.9560509554140127, 0.5628642797668609, 0.9875941515285778, 0.9890335846470185, 0.9803808424697057, 0.6910397295012679, 0.9785596481583287, 0.9961505560307955, 0.9968612680477087, 0.9957716701902748]\n",
      "[[22760  1983]\n",
      " [ 1706 18519]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     24743\n",
      "           1       0.90      0.92      0.91     20225\n",
      "\n",
      "    accuracy                           0.92     44968\n",
      "   macro avg       0.92      0.92      0.92     44968\n",
      "weighted avg       0.92      0.92      0.92     44968\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [TN, FP, FN, TP]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(acc_score)\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print(classification_report(Truth, Output))\n",
    "print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [44:20, 115.69s/it]\n"
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=23)\n",
    "#for df in features_df_list:\n",
    "df = features_maindf\n",
    "acc_score = [];\n",
    "Truth = [];\n",
    "Output = [];\n",
    "#confusion_matrix_df = pd.DataFrame(columns=['TN', 'FP', 'FN', 'TP'])\n",
    "for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "    train_index = ~df['Subject'].str.contains(subject)\n",
    "    test_index = df['Subject'].str.contains(subject)\n",
    "    X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "    y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "\n",
    "    model =  GradientBoostingClassifier(n_estimators = 500, \n",
    "                                           learning_rate = 0.1, \n",
    "                                           max_depth = 4, \n",
    "                                           random_state = 2)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    pred_values = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "    acc = accuracy_score(y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "    #confusion_matrix_df.loc[idx] = confusion_matrix(Truth, Output).ravel()\n",
    "    Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "    Output.extend(pred_values); ## it is a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9136155606407322, 0.9565922920892495, 0.9955919395465995, 0.9298561151079137, 0.9968652037617555, 0.9594320486815415, 0.7603923400280242, 0.998638529611981, 0.9397590361445783, 0.9680264608599779, 0.9832123411978222, 0.9899497487437185, 0.8444444444444444, 0.9464968152866242, 0.6149042464612823, 0.9884802835622508, 0.9883481836874571, 0.9849971148297749, 0.7603550295857988, 0.9494227597581089, 0.9948674080410608, 0.9962335216572504, 0.9949260042283298]\n",
      "[[23139  1604]\n",
      " [ 1738 18487]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     24743\n",
      "           1       0.92      0.91      0.92     20225\n",
      "\n",
      "    accuracy                           0.93     44968\n",
      "   macro avg       0.93      0.92      0.92     44968\n",
      "weighted avg       0.93      0.93      0.93     44968\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [TN, FP, FN, TP]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(acc_score)\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print(classification_report(Truth, Output))\n",
    "print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
