{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMS-Sapkals\\AppData\\Local\\Temp\\ipykernel_20036\\4110068169.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('retina')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 70 #display 70 dpi in Jupyter Notebook, may consider100 dpi \n",
    "plt.rcParams['savefig.dpi'] = 300 #define 300 dpi for saving figures\n",
    "\n",
    "import seaborn as sns\n",
    "## here are some settings \n",
    "sns.set_style('whitegrid')\n",
    "sns.set(rc={\"figure.dpi\":70, 'savefig.dpi':300}) #defining dpi setting\n",
    "sns.set_context('notebook')\n",
    "sns.set_style(\"ticks\")\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "---Run time is 0.00012390001211315393 seconds ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tells matplotlib to display images inline instead of a new window\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "import timeit #imports timeit module\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "start_time = timeit.default_timer() #defines start time so computational time can be calculated\n",
    "print(\"Hello World\")\n",
    "elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "print(\"---Run time is %s seconds ---\" % elapsed) #prints computation time\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import statistics\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import neighbors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tqdm import tqdm\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampto must be greater than sampfrom\n",
      "sampto must be greater than sampfrom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:15<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# cwd = os.getcwd()\n",
    "# print(cwd)\n",
    "# os.chdir('/Users/chenc/000---STT450-Jupyter Notebook/000--STT450-550/') \n",
    "#data = load_breast_cancer(as_frame = True); \n",
    "#df = data.frame; \n",
    "#print(df.shape)\n",
    "# In this block use the code we looked at on 6/30 as a reference to save our rr-intervals as a .\n",
    "rlist = []\n",
    "records = 'mit-bih-raw\\RECORDS' # Replace the _______ with the name of the records file in your MIT-BIH data folder\n",
    "with open(records) as rfile: #Then we open the file \n",
    "                             #The 'with' command only opens the file while we are in it. Automatically closes the file when we're not\n",
    "    for record in rfile:  # Then we iterate through the lines in the file\n",
    "        record = record[0:len(record)-1] # Remove any erronious new line characters at the end ('\\n')\n",
    "        rlist.append(record) # Then build an array with it\n",
    "        \n",
    "\n",
    "###### Step 1: Initialize all Arrays\n",
    "             # Below, replace all of the ___ with the command that declares an array/list\n",
    "             # hint: https://stackoverflow.com/questions/1514553/how-to-declare-an-array-in-python\n",
    "samples = [] # will house the samples of all subjects\n",
    "good_list = [] # will list the names of the subjects we successfully extracted\n",
    "bad_list = [] # will house the names of the subjects we failed to extract\n",
    "qrs = [] # will house the indices of R-Peaks for all subjects\n",
    "atr_label = [] # will house the labels for each rhythm annotation for all subjects\n",
    "atr_locs = [] # will house the locations corresponding to the rhythm annotation labels\n",
    "\n",
    "\n",
    "###### Step 2: Extract Information\n",
    "for x in tqdm(rlist): #this will iterate through te records that we found above\n",
    "  \n",
    "    try: # A try statement will run the except statement if for some reason the try commands fail\n",
    "         # In this case I use the try statement because one of the subjects has no signal data causing failure\n",
    "         # I then use bad_list and good_list so that all of the indices in rlist match with the arrays we initialized in Step 1, above\n",
    "        ######################################################\n",
    "            # Below find the wfdb function that will return the information that is described below \n",
    "        # Then replace _____ with the correct function call\n",
    "        samp = wfdb.rdsamp('mit-bih-raw/'+x) # wfdb._____(file_location) will read the signal & header data and return a 2 value array\n",
    "            # samp[0] - the signal data is the raw reading from the ecg. Each value is a sample taken.\n",
    "            # samp[1] - the header data includes things about the signal data such as:\n",
    "              # samples per section, denoted 'fs'\n",
    "              # number of signals, denoted 'n_sig'\n",
    "            \n",
    "        ######################################################\n",
    "        samples.append(samp) #add it to our array for all subject\n",
    "            #What is our file extension that has the annotation we want? Find it here and replace _____ with it \n",
    "            #hint: READ THE VARIABLE NAMES!!!!\n",
    "        qrs_tmp = wfdb.rdann('mit-bih-raw/'+x, extension='qrs') #extract the QRS Info\n",
    "        qrs_locs = np.array(qrs_tmp.sample, dtype='int') #Get just the loccation of R-Peaks from the QRS Info\n",
    "        qrs.append(qrs_locs) # Add to our array for all subjects\n",
    "        \n",
    "            #Do the same thing here\n",
    "        atr = wfdb.rdann('mit-bih-raw/'+x,extension='atr') #extract the atr info which stores the rhythm type(s) over the whole signal\n",
    "        atr_label.append(atr.aux_note) # aux_note stores the type of rhythm - main two are '(N' for normal and '(AFIB' for AFIB\n",
    "        atr_locs.append(np.append(atr.sample, len(samp[0]))) #I add the length of the whole sample to the end for better visualization later\n",
    "        \n",
    "        good_list.append(x) # when all extraction is successful append the record name to good_list\n",
    "    except Exception as exep:\n",
    "        print(exep) # Alert the user of an exception\n",
    "        bad_list.append(x) # add to the bad list\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = pd.read_csv('Data/Carseats.csv')\n",
    "# #df3.info()\n",
    "# print(); df3.head(5)\n",
    "features_df_list = []\n",
    "for subject in good_list:\n",
    "    data = pd.read_csv(f'subject-features-dataframes/subject{subject}.csv')\n",
    "    data = data.assign(Subject = subject)\n",
    "    #print(data)\n",
    "    features_df_list.append(data)\n",
    "features_maindf = pd.concat(features_df_list, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['High'] = df3.Sales.map(lambda x: 1 if x>8 else 0)\n",
    "# df3.ShelveLoc = pd.factorize(df3.ShelveLoc)[0]\n",
    "# df3.Urban = df3.Urban.map({'No':0, 'Yes':1})\n",
    "# df3.US = df3.US.map({'No':0, 'Yes':1})\n",
    "# #df3.info()\n",
    "# print(); df3.head(5)\n",
    "#X = df3.drop(['Sales', 'High'], axis = 1)\n",
    "#y = df3.High\n",
    "##print(X.shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = ['StoS', 'StoR', 'StoL', 'RtoS', 'RtoR', 'RtoL', 'LtoS',\n",
    "       'LtoR', 'LtoL', 'STD', 'CoefVar', 'Range', 'Volatility', 'ShEn',\n",
    "       'AppEn', 'SampEn']\n",
    "y_values = ['Rhythm']\n",
    "#features_df_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "criterion{“gini”, “entropy”}, default=”gini”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for df in features_df_list:\n",
    "# #model = DecisionTreeClassifier(max_depth = 6) #criterion='entropy'\n",
    "# df = features_maindf\n",
    "# acc_score = [];\n",
    "# Truth = [];\n",
    "# Output = [];\n",
    "# max_depth_list = []\n",
    "# n_estimators_list = []\n",
    "# for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "#     train_index = ~df['Subject'].str.contains(subject)\n",
    "#     test_index = df['Subject'].str.contains(subject)\n",
    "#     X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "#     y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "\n",
    "#     temp_model = DecisionTreeClassifier(max_depth = 6)    \n",
    "#     param_distributions = {'max_depth': randint(7,9),\n",
    "#                           'nestim'}\n",
    "\n",
    "#     search = RandomizedSearchCV(estimator=temp_model, param_distributions=param_distributions, random_state=0)\n",
    "#     search.fit(X_train, y_train)\n",
    "\n",
    "#     n_estimators_list.append(search.best_params_['n_estimators'])\n",
    "#     max_depth_list.append(search.best_params_['max_depth'])\n",
    "    \n",
    "#     model = DecisionTreeClassifier(max_depth = 8) #criterion='entropy'\n",
    "#     model.fit(X_train,y_train)\n",
    "\n",
    "#     pred_values = model.predict(X_test)\n",
    "#     pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "#     acc = accuracy_score(y_test, pred_values)\n",
    "#     acc_score.append(acc)\n",
    "    \n",
    "#     Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "#     Output.extend(pred_values); ## it is a list \n",
    "# elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "# print(\"---Run time is %s seconds ---\" % elapsed) #prints computation time\n",
    "# print()\n",
    "\n",
    "# print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "# print()\n",
    "# print('Avg accuracy : \\n{}'.format(np.mean(acc_score))); \n",
    "# print()\n",
    "# print('Std of accuracy : \\n{}'.format(np.std(acc_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(confusion_matrix(Truth, Output))\n",
    "# print(classification_report(Truth, Output))\n",
    "# print(acc_score)\n",
    "# print(elapsed)\n",
    "# #print(n_estimators_list)\n",
    "# # print(max_depth_list)\n",
    "\n",
    "# # temp_list = []\n",
    "# # temp_idx = []\n",
    "# # for acc in acc_score:\n",
    "# #     if acc >= 0.95:\n",
    "# #         temp_list.append(acc)\n",
    "# #         temp_idx.append(acc_score.index(acc))\n",
    "# # for idx in temp_idx:\n",
    "# #     print(max_depth_list[idx])\n",
    "    \n",
    "# # statistics.mode(max_depth_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[22543  2200]\n",
    "#  [ 2067 18158]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.92      0.91      0.91     24743\n",
    "#            1       0.89      0.90      0.89     20225\n",
    "\n",
    "#     accuracy                           0.91     44968\n",
    "#    macro avg       0.90      0.90      0.90     44968\n",
    "# weighted avg       0.91      0.91      0.91     44968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[22796  1947]\n",
    "#  [ 1763 18462]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.93      0.92      0.92     24743\n",
    "#            1       0.90      0.91      0.91     20225\n",
    "\n",
    "#     accuracy                           0.92     44968\n",
    "#    macro avg       0.92      0.92      0.92     44968\n",
    "# weighted avg       0.92      0.92      0.92     44968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg accuracy : \n",
    "# 0.9225946312949485\n",
    "\n",
    "# Std of accuracy : \n",
    "# 0.10175840774589326\n",
    "\n",
    "# [[22670  2073]\n",
    "#  [ 1762 18463]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.93      0.92      0.92     24743\n",
    "#            1       0.90      0.91      0.91     20225\n",
    "\n",
    "#     accuracy                           0.91     44968\n",
    "#    macro avg       0.91      0.91      0.91     44968\n",
    "# weighted avg       0.91      0.91      0.91     44968"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The exact results obtained in this section may\n",
    "depend on the version of `python` and the version of the `RandomForestRegressor` package\n",
    "installed on your computer, so don't stress out if you don't match up exactly with the book. Recall that **bagging** is simply a special case of\n",
    "a **random forest** with $m = p$. Therefore, the `RandomForestRegressor()` function can\n",
    "be used to perform both random forests and bagging. Let's start with bagging:\n",
    "\n",
    "\n",
    "### Bagging: using all features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging: use p for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [4:14:35, 664.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Run time is 15291.779910900004 seconds ---\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.9130434782608695, 0.9505070993914807, 0.9955919395465995, 0.9244604316546763, 0.9973876698014629, 0.954158215010142, 0.7986921999065857, 0.9979577944179714, 0.9417670682730924, 0.9680264608599779, 0.9813974591651543, 0.9885139985642498, 0.8326530612244898, 0.9471337579617835, 0.6144879267277269, 0.9871510855117412, 0.9869773817683345, 0.9873052510098096, 0.7303465765004227, 0.9708631115997801, 0.9931565440547476, 0.997489014438167, 0.9953488372093023]\n",
      "\n",
      "Avg accuracy : \n",
      "0.9328007114286333\n",
      "\n",
      "Std of accuracy : \n",
      "0.09622327149837745\n",
      "[[23035  1708]\n",
      " [ 1652 18573]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     24743\n",
      "           1       0.92      0.92      0.92     20225\n",
      "\n",
      "    accuracy                           0.93     44968\n",
      "   macro avg       0.92      0.92      0.92     44968\n",
      "weighted avg       0.93      0.93      0.93     44968\n",
      "\n",
      "[0.9130434782608695, 0.9505070993914807, 0.9955919395465995, 0.9244604316546763, 0.9973876698014629, 0.954158215010142, 0.7986921999065857, 0.9979577944179714, 0.9417670682730924, 0.9680264608599779, 0.9813974591651543, 0.9885139985642498, 0.8326530612244898, 0.9471337579617835, 0.6144879267277269, 0.9871510855117412, 0.9869773817683345, 0.9873052510098096, 0.7303465765004227, 0.9708631115997801, 0.9931565440547476, 0.997489014438167, 0.9953488372093023]\n",
      "15291.779910900004\n",
      "[127, 130, 127, 132, 132, 132, 127, 127, 132, 122, 127, 132, 128, 116, 134, 127, 127, 130, 138, 127, 138, 122, 130]\n",
      "[13, 11, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 12, 13, 13, 11, 11, 13, 11, 13, 11]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 61>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m temp_idx:\n\u001b[0;32m     62\u001b[0m     n_estimators_best\u001b[38;5;241m.\u001b[39mappend(n_estimators_list[idx])\n\u001b[1;32m---> 63\u001b[0m     \u001b[43mmax_depth_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_depth_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=23)\n",
    "#for df in features_df_list:\n",
    "df = features_maindf\n",
    "acc_score = [];\n",
    "Truth = [];\n",
    "Output = [];\n",
    "n_estimators_list = []\n",
    "max_depth_list = []\n",
    "#confusion_matrix_df = pd.DataFrame(columns=['TN', 'FP', 'FN', 'TP'])\n",
    "for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "    train_index = ~df['Subject'].str.contains(subject)\n",
    "    test_index = df['Subject'].str.contains(subject)\n",
    "    X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "    y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "    \n",
    "    temp_model = RandomForestClassifier(max_features=16,random_state = 2)    \n",
    "    param_distributions = {'max_depth': randint(11,14),\n",
    "                          'n_estimators': randint(115,139)}\n",
    "\n",
    "    search = RandomizedSearchCV(estimator=temp_model, param_distributions=param_distributions, random_state=0)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    n_estimators_list.append(search.best_params_['n_estimators'])\n",
    "    max_depth_list.append(search.best_params_['max_depth'])\n",
    "    \n",
    "    model = RandomForestClassifier(max_features = 16, random_state = 2, max_depth=search.best_params_['max_depth'], n_estimators=search.best_params_['n_estimators'])\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    pred_values = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "    acc = accuracy_score(y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "    #confusion_matrix_df.loc[idx] = confusion_matrix(Truth, Output).ravel()\n",
    "    Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "    Output.extend(pred_values); ## it is a list \n",
    "elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "print(\"---Run time is %s seconds ---\" % elapsed) #prints computation time\n",
    "print()\n",
    "\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print()\n",
    "print('Avg accuracy : \\n{}'.format(np.mean(acc_score))); \n",
    "print()\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print(classification_report(Truth, Output))\n",
    "print(acc_score)\n",
    "print(elapsed)\n",
    "print(n_estimators_list)\n",
    "print(max_depth_list)\n",
    "temp_list = []\n",
    "temp_idx = []\n",
    "n_estimators_best = []\n",
    "max_depth_best = []\n",
    "for acc in acc_score:\n",
    "    if acc >= 0.95:\n",
    "        temp_list.append(acc)\n",
    "        temp_idx.append(acc_score.index(acc))\n",
    "for idx in temp_idx:\n",
    "    n_estimators_best.append(n_estimators_list[idx])\n",
    "    max_depth_best.append(max_depth_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.mode([13, 11, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 12, 13, 13, 11, 11, 13, 11, 13, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acc in acc_score:\n",
    "    if acc >= 0.95:\n",
    "        temp_list.append(acc)\n",
    "        temp_idx.append(acc_score.index(acc))\n",
    "for idx in temp_idx:\n",
    "    n_estimators_best.append(n_estimators_list[idx])\n",
    "    max_depth_best.append(max_depth_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [06:26, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Run time is 693.3505415000109 seconds ---\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.9130434782608695, 0.9496957403651115, 0.9955919395465995, 0.9238609112709832, 0.9973876698014629, 0.9545638945233266, 0.7986921999065857, 0.9979577944179714, 0.9422690763052208, 0.9685777287761852, 0.9813974591651543, 0.9885139985642498, 0.8331065759637188, 0.9503184713375796, 0.6194837635303914, 0.9871510855117412, 0.9869773817683345, 0.9873052510098096, 0.7417582417582418, 0.9708631115997801, 0.9918733960650128, 0.997489014438167, 0.9961945031712474]\n",
      "\n",
      "Avg accuracy : \n",
      "0.9336553342199018\n",
      "\n",
      "Std of accuracy : \n",
      "0.09447902543178308\n",
      "[[23064  1679]\n",
      " [ 1637 18588]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     24743\n",
      "           1       0.92      0.92      0.92     20225\n",
      "\n",
      "    accuracy                           0.93     44968\n",
      "   macro avg       0.93      0.93      0.93     44968\n",
      "weighted avg       0.93      0.93      0.93     44968\n",
      "\n",
      "[0.9130434782608695, 0.9496957403651115, 0.9955919395465995, 0.9238609112709832, 0.9973876698014629, 0.9545638945233266, 0.7986921999065857, 0.9979577944179714, 0.9422690763052208, 0.9685777287761852, 0.9813974591651543, 0.9885139985642498, 0.8331065759637188, 0.9503184713375796, 0.6194837635303914, 0.9871510855117412, 0.9869773817683345, 0.9873052510098096, 0.7417582417582418, 0.9708631115997801, 0.9918733960650128, 0.997489014438167, 0.9961945031712474]\n",
      "693.3505415000109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_estimators_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 54>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(acc_score)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(elapsed)\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mn_estimators_list\u001b[49m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(max_depth_list)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_estimators_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#for df in features_df_list:\n",
    "df = features_maindf\n",
    "acc_score = [];\n",
    "Truth = [];\n",
    "Output = [];\n",
    "# n_estimators_list = []\n",
    "# max_depth_list = []\n",
    "import statistics\n",
    "#mode_depth = statistics.mode(max_depth_best)\n",
    "#mode_estimators = statistics.mode(n_estimators_best)\n",
    "#confusion_matrix_df = pd.DataFrame(columns=['TN', 'FP', 'FN', 'TP'])\n",
    "for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "    train_index = ~df['Subject'].str.contains(subject)\n",
    "    test_index = df['Subject'].str.contains(subject)\n",
    "    X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "    y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "    \n",
    "#     temp_model = RandomForestClassifier(max_features=16,random_state = 2)    \n",
    "#     param_distributions = {'max_depth': randint(11,14),\n",
    "#                           'n_estimators': randint(115,139)}\n",
    "\n",
    "#     search = RandomizedSearchCV(estimator=temp_model, param_distributions=param_distributions, random_state=0)\n",
    "#     search.fit(X_train, y_train)\n",
    "\n",
    "#     n_estimators_list.append(search.best_params_['n_estimators'])\n",
    "#     max_depth_list.append(search.best_params_['max_depth'])\n",
    "    \n",
    "    model = RandomForestClassifier(max_features = 16, random_state = 2, max_depth=13, \n",
    "                                   n_estimators=127)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    pred_values = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "    acc = accuracy_score(y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "    #confusion_matrix_df.loc[idx] = confusion_matrix(Truth, Output).ravel()\n",
    "    Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "    Output.extend(pred_values); ## it is a list \n",
    "elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "print(\"---Run time is %s seconds ---\" % elapsed) #prints computation time\n",
    "print()\n",
    "\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print()\n",
    "print('Avg accuracy : \\n{}'.format(np.mean(acc_score))); \n",
    "print()\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print(classification_report(Truth, Output))\n",
    "print(acc_score)\n",
    "print(elapsed)\n",
    "print(n_estimators_list)\n",
    "print(max_depth_list)\n",
    "# temp_list = []\n",
    "# temp_idx = []\n",
    "# for acc in acc_score:\n",
    "#     if acc >= 0.95:\n",
    "#         temp_list.append(acc)\n",
    "#         temp_idx.append(acc_score.index(acc))\n",
    "# for idx in temp_idx:\n",
    "#     print(n_estimators_list[idx])\n",
    "#     print(max_depth_list[idx])\n",
    "# print(confusion_matrix(Truth, Output))\n",
    "# print(classification_report(Truth, Output))\n",
    "# print(acc_score)\n",
    "# print(elapsed)\n",
    "# print(n_estimators_list)\n",
    "# print(max_depth_list)\n",
    "\n",
    "# temp_list = []\n",
    "# temp_idx = []\n",
    "# for acc in acc_score:\n",
    "#     if acc >= 0.95:\n",
    "#         temp_list.append(acc)\n",
    "#         temp_idx.append(acc_score.index(acc))\n",
    "# for idx in temp_idx:\n",
    "#     print(n_estimators_list[idx])\n",
    "#     print(max_depth_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [02:25,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Run time is 1262.5597275000036 seconds ---\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.9061784897025171, 0.9456389452332657, 0.9955919395465995, 0.908273381294964, 0.9952978056426333, 0.9440162271805274, 0.8397944885567492, 0.9972770592239619, 0.9332329317269076, 0.958103638368247, 0.9818511796733213, 0.9849246231155779, 0.782312925170068, 0.9738853503184713, 0.5578684429641965, 0.973859105006646, 0.9835503769705277, 0.9930755914598961, 0.7071005917159763, 0.9763606377130292, 0.9914456800684346, 0.9899560577526679, 0.9839323467230444]\n",
      "\n",
      "Avg accuracy : \n",
      "0.9262403397881838\n",
      "\n",
      "Std of accuracy : \n",
      "0.10672839222741957\n",
      "[[22771  1972]\n",
      " [ 1738 18487]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     24743\n",
      "           1       0.90      0.91      0.91     20225\n",
      "\n",
      "    accuracy                           0.92     44968\n",
      "   macro avg       0.92      0.92      0.92     44968\n",
      "weighted avg       0.92      0.92      0.92     44968\n",
      "\n",
      "[0.9061784897025171, 0.9456389452332657, 0.9955919395465995, 0.908273381294964, 0.9952978056426333, 0.9440162271805274, 0.8397944885567492, 0.9972770592239619, 0.9332329317269076, 0.958103638368247, 0.9818511796733213, 0.9849246231155779, 0.782312925170068, 0.9738853503184713, 0.5578684429641965, 0.973859105006646, 0.9835503769705277, 0.9930755914598961, 0.7071005917159763, 0.9763606377130292, 0.9914456800684346, 0.9899560577526679, 0.9839323467230444]\n",
      "1262.5597275000036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = features_maindf\n",
    "acc_score = [];\n",
    "Truth = [];\n",
    "Output = [];\n",
    "# n_estimators_list = []\n",
    "# max_depth_list = []\n",
    "import statistics\n",
    "#mode_depth = statistics.mode(max_depth_best)\n",
    "#mode_estimators = statistics.mode(n_estimators_best)\n",
    "#confusion_matrix_df = pd.DataFrame(columns=['TN', 'FP', 'FN', 'TP'])\n",
    "for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "    train_index = ~df['Subject'].str.contains(subject)\n",
    "    test_index = df['Subject'].str.contains(subject)\n",
    "    X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "    y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "    \n",
    "#     temp_model = RandomForestClassifier(max_features=16,random_state = 2)    \n",
    "#     param_distributions = {'max_depth': randint(11,14),\n",
    "#                           'n_estimators': randint(115,139)}\n",
    "\n",
    "#     search = RandomizedSearchCV(estimator=temp_model, param_distributions=param_distributions, random_state=0)\n",
    "#     search.fit(X_train, y_train)\n",
    "\n",
    "#     n_estimators_list.append(search.best_params_['n_estimators'])\n",
    "#     max_depth_list.append(search.best_params_['max_depth'])\n",
    "    \n",
    "    model = RandomForestClassifier(max_features = 16, random_state = 2, max_depth=5)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    pred_values = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "    acc = accuracy_score(y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "    #confusion_matrix_df.loc[idx] = confusion_matrix(Truth, Output).ravel()\n",
    "    Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "    Output.extend(pred_values); ## it is a list \n",
    "elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "print(\"---Run time is %s seconds ---\" % elapsed) #prints computation time\n",
    "print()\n",
    "\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print()\n",
    "print('Avg accuracy : \\n{}'.format(np.mean(acc_score))); \n",
    "print()\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print(classification_report(Truth, Output))\n",
    "print(acc_score)\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "statistics.mode(n_estimators_list)\n",
    "statistics.mode(max_depth_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[23029  1714]\n",
    "#  [ 1649 18576]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.93      0.93      0.93     24743\n",
    "#            1       0.92      0.92      0.92     20225\n",
    "\n",
    "#     accuracy                           0.93     44968\n",
    "#    macro avg       0.92      0.92      0.92     44968\n",
    "# weighted avg       0.93      0.93      0.93     44968\n",
    "# ---Run time is 27743.89577069995 seconds ---\n",
    "\n",
    "# Accuracy of each fold: \n",
    "#  [0.914187643020595, 0.9509127789046653, 0.9955919395465995, 0.9250599520383693, 0.9973876698014629, 0.9565922920892495, 0.79542269967305, 0.9979577944179714, 0.9422690763052208, 0.9680264608599779, 0.9813974591651543, 0.9885139985642498, 0.8335600907029479, 0.9496815286624204, 0.6186511240632806, 0.9858218874612317, 0.9876627827278959, 0.9855741488747836, 0.7324598478444633, 0.971412864211105, 0.9940119760479041, 0.997489014438167, 0.9936575052854123]\n",
    "\n",
    "# Avg accuracy : \n",
    "# 0.9331870667263553\n",
    "\n",
    "# Std of accuracy : \n",
    "# 0.09555730626481958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidation = KFold(n_splits=23)\n",
    "# #for df in features_df_list:\n",
    "# df = features_maindf\n",
    "# acc_score = [];\n",
    "# Truth = [];\n",
    "# Output = [];\n",
    "# for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "#     train_index = ~df['Subject'].str.contains(subject)\n",
    "#     test_index = df['Subject'].str.contains(subject)\n",
    "#     X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "#     y_train , y_test = df.loc[train_index,y_values], df.loc[test_index,y_values]\n",
    "\n",
    "#     model = RandomForestClassifier(max_features = 10, random_state = 2)\n",
    "#     model.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#     pred_values = model.predict(X_test)\n",
    "#     pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "#     acc = accuracy_score(y_test, pred_values)\n",
    "#     acc_score.append(acc)\n",
    "    \n",
    "#     Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "#     Output.extend(pred_values); ## it is a list \n",
    "\n",
    "\n",
    "# model = RandomForestClassifier(max_features = 16, random_state = 2)\n",
    "# scores = cross_val_score(model, X, y, cv=crossvalidation)\n",
    "# print('Accuracy of each fold: \\n {}'.format(scores))\n",
    "# print()\n",
    "# print(\"Avg accuracy: {}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An AdaBoost classifier.\n",
    "\n",
    "The argument `n_estimators = 500` indicates that we want 500 trees\n",
    "\n",
    "class sklearn.ensemble.AdaBoostClassifier(base_estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidation = KFold(n_splits=23)\n",
    "# #for df in features_df_list:\n",
    "# df = features_maindf\n",
    "# acc_score = [];\n",
    "# Truth = [];\n",
    "# Output = [];\n",
    "# for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "#     train_index = ~df['Subject'].str.contains(subject)\n",
    "#     test_index = df['Subject'].str.contains(subject)\n",
    "#     X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "#     y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "\n",
    "#     model = AdaBoostClassifier(n_estimators=500, learning_rate = 0.1, algorithm=\"SAMME.R\", random_state=2)\n",
    "#     model.fit(X_train,y_train)\n",
    "\n",
    "#     pred_values = model.predict(X_test)\n",
    "#     pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "#     acc = accuracy_score(y_test, pred_values)\n",
    "#     acc_score.append(acc)\n",
    "    \n",
    "#     Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "#     Output.extend(pred_values); ## it is a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(acc_score)\n",
    "# print(confusion_matrix(Truth, Output))\n",
    "# print(classification_report(Truth, Output))\n",
    "# print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidation = KFold(n_splits=23)\n",
    "# #for df in features_df_list:\n",
    "# df = features_maindf\n",
    "# acc_score = [];\n",
    "# Truth = [];\n",
    "# Output = [];\n",
    "# #confusion_matrix_df = pd.DataFrame(columns=['TN', 'FP', 'FN', 'TP'])\n",
    "# for idx, subject in tqdm(enumerate(good_list)):\n",
    "    \n",
    "#     train_index = ~df['Subject'].str.contains(subject)\n",
    "#     test_index = df['Subject'].str.contains(subject)\n",
    "#     X_train , X_test = df.loc[train_index,x_values], df.loc[test_index,x_values]\n",
    "#     y_train , y_test = df.loc[train_index,y_values].values.ravel(), df.loc[test_index,y_values]\n",
    "\n",
    "#     model =  GradientBoostingClassifier(n_estimators = 500, \n",
    "#                                            learning_rate = 0.1, \n",
    "#                                            max_depth = 4, \n",
    "#                                            random_state = 2)\n",
    "#     model.fit(X_train,y_train)\n",
    "\n",
    "#     pred_values = model.predict(X_test)\n",
    "#     pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "     \n",
    "#     acc = accuracy_score(y_test, pred_values)\n",
    "#     acc_score.append(acc)\n",
    "#     #confusion_matrix_df.loc[idx] = confusion_matrix(Truth, Output).ravel()\n",
    "#     Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "#     Output.extend(pred_values); ## it is a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(acc_score)\n",
    "# print(confusion_matrix(Truth, Output))\n",
    "# print(classification_report(Truth, Output))\n",
    "# print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afib",
   "language": "python",
   "name": "afib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
